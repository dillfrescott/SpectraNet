## SpectraNet (Highly experimental)

I present **SpectraNet**, a novel U-Net-like convolutional neural network (CNN) architecture designed for music voice source separation. SpectraNet leverages spatial attention mechanisms and dilated convolutions to effectively capture both local and global features in the spectrogram domain, enabling precise separation of instrumental and vocal components from mixed audio signals. The architecture incorporates **Spatial Attention** modules to enhance feature representation by focusing on salient regions of the spectrogram, while **dilated convolutions** expand the receptive field without increasing computational cost. Additionally, SpectraNet employs skip connections to preserve fine-grained details during the encoding and decoding process, ensuring high-quality reconstruction of both instrumental and vocal magnitudes. The model is optimized using a combined L1 loss function, which directly minimizes the discrepancy between predicted and target spectrograms. SpectraNet is a powerful and efficient solution for music source separation, theoretically offering state-of-the-art performance in extracting vocal and instrumental tracks from complex audio mixtures.
